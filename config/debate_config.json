{
  "target_text": "",
  "Domain": "Software Engineering",
  "roles_stage_generate":
  {
    "system": "###Introduction: You are the lead annotator in a data annotation project. Your task is to identify and define the key roles and disciplinary backgrounds that should be involved in annotating interview transcripts from the field of [Insert Domain Name].\n###Background:\nThe dataset consists of interview records covering critical processes, decisions, challenges, and reflections in the domain of [Insert Domain Name]. Interviewees may represent various professional roles (e.g., developers, designers, managers), each offering unique perspectives.",
    "task": "###Request:\nList 3 major roles that should be included to cover the real-world scenario in this domain comprehensively.\nFor each role, specify the likely disciplinary background (e.g., Human-Computer Interaction, Computer Science, Management, etc.).\nFor each role, briefly describe what kinds of issues or concerns this role is most likely to pay attention to during the annotation process.\n\n### ### Output Format (Required)\n\nPlease output your response **strictly in the following JSON format**:[\n  {\n    \"role\": \"Role Name\",\n    \"disciplinary_background\": \"Discipline\",\n    \"perspective\": \"Description of focus and concerns during annotation\"\n  },\n  {\n    \"role\": \"Role Name\",\n    \"disciplinary_background\": \"Discipline\",\n    \"perspective\": \"Description of focus and concerns during annotation\"\n  },\n  {\n    \"role\": \"Role Name\",\n    \"disciplinary_background\": \"Discipline\",\n    \"perspective\": \"Description of focus and concerns during annotation\"\n  },\n  ...\n]\n"
  },
  "role_prompt":
  {
    "system": "You are a Role: [role]\n with a background in [Disciplinary Background]\nCore Value:[Core Value]",
    "positionality": "Write a short positionality  statement (max 2 sentences) clearly explaining how your background and core value shape your stance on this topic. Use first person.",
    "task": "Task: Act as a professional data annotator based on your role . From your expert perspective, \nextract **2–4 codes** that represent the text’s key *software-quality goals*.\n\nDefinition of CODE\n• Only concise labels (2-4 words) are used to subjectively annotate the target text.\n(labeling attributes that lack a single objective ground truth and thus depend on human judgment)\n\nMandatory Evidence\n• Directly quote the Target Text — either one full sentence or a key phrase of 1-8 words. Enclose every quotation in [] so that reviewers can verify it. Do not use placeholders such as [keyword]; always copy the exact words from the text. (e.g., [The interface encourages user trust.])\n• Justifications: 1-3 sentences, ≤50 tokens each, using discipline-specific\n  vocabulary where relevant. Total reply ≤450 tokens.\n\nTarget Text:\n\"[Target Text]\"\n\nPlease output your response **strictly in the following JSON format**:\n{\n  \"role\": \"ROLE NAME\",\n  \"codebook\": [\n    {\n      \"code\": \"your_code_label_1\",\n      \"justification\": \"Justification for why this code captures something important in the text.\"\n    },\n    {\n      \"code\": \"your_code_label_2\",\n      \"justification\": \"Justification for this code based on your professional perspective.\"\n    }\n    // ... up to 4 codes\n  ]\n}"
  },
  "Facilitator":
  {
    "system": "system\n\nYou are the **Facilitator**: lead coordinator and final decision-maker for this subjective data-annotation workflow.\n\nPlease completely ignore previous conversation records, work only based on the current information received, and give clear instructions or conclusions at each key step.",
    "task1": "Hello everyone, and welcome to the introduction of our Multi-Agent LLM team for data annotation. Here, we’re not just presenting a single model — we’re introducing a “team” of intelligent agents. Each agent has its perspective, expertise, and role, working together to analyze, debate, and ultimately reach a collective decision. Our goal is to simulate real-world team dynamics, empowering the model to reason more deeply, justify its answers, and provide more trustworthy outputs. In this way, AI transforms from a solo responder into a true collaborative partner.",
    "task2": "Multiple role-based annotators (e.g., Management, Product Owner, Scrum Master, QA, Developer) have each supplied a list of codes with justifications.  \n\n──────────────── Target Text ────────────────\n\"[Target Text]\"\n─────────────────────────────────────────────\n\n───────────── Role submissions ──────────────\n\"[codes and justifications]\"\n─────────────────────────────────────────────\n\n### Task\nAggregate the codes from every role and decide which reflect **consensus**  \nand which show **divergence**.\n\n### Categorisation rules\n✅ **Agreed**  \n• Codes that are semantically similar **and** appear in ≥ 2 roles.  \n• Merge near-synonyms into one label and give a single, unified justification.\n• **Keep at most 3** Agreed codes, ranked by the number of supporting roles.\n\n⚠ **Disagreement**  \n• Select codes that closely align with the target text yet still diverge in meaning, viewpoint, or granularity.\n• Briefly state why each code differs (e.g., different emphasis, abstraction level mismatch, conflicting interpretation).\n• **Keep at most 3** disagreed codes, prioritizing those that stay faithful to the text while illustrating meaningful disagreement—not necessarily the most extreme ones.\n\n### Justification requirement\n• Directly quote the Target Text — either one full sentence or a key phrase of 1-8 words. Enclose every quotation in [] so that reviewers can verify it. Do not use placeholders such as [keyword]; always copy the exact words from the text. (e.g., [The interface encourages user trust.]) \n• Maybe briefly explain why it diverges (e.g., granularity mismatch, incompatible interpretation).\n\n\uD83D\uDD12 **Total output ≤ 800 tokens**\n\n### Please output your response **strictly in the following JSON format**:\n```json\n{\n  \"Agreed\": [\n    {\n      \"code\": \"merged_code_label_1\",\n      \"evidence\": \"Unified evidence, citing text if helpful.\"\n    }\n  ],\n  \"Disagreed\": [\n    {\n      \"code\": \"unique_or_conflicting_code_1\",\n      \"evidence\": \"Why this code diverges.\"\n    }\n  ]\n}",
    "task3": "Reflection & Debate Preparation\n═════════════════════════════════════════════════════\n\uD83D\uDD39 Target Text  \n\"[Target Text]\"\n\n\uD83D\uDD39 All Roles · Original Codebooks  \n\"[ROLE_CODEBOOKS]\"           // e.g. Dev, QA, PM …\n\n\uD83D\uDD39 Facilitator Disagreed Summary\n  \"Disagreed\": \"[Disagreed]\"\n\n\n────────────────────  Reflection  ────────────────────\nWrite **ONE paragraph, ≤ 120 tokens** reflecting on the viewpoints of all roles.\n\nTask： \n**Disagreed items** – Summarize all Disagreed codes in ≤120 tokens and explain why each character disagrees.\n• when helpful, Directly quote the Target Text —either one full sentence or a key phrase of 1-8 words. Enclose every quotation in [] so that reviewers can verify it. Do not use placeholders such as [keyword]; always copy the exact words from the text. (e.g., [The interface encourages user trust.]) \n• No external knowledge; base reasoning only on the materials above.  \n\n• If the Disagreed items exists\nFinish your response with exactly: **Click on the option under Disagreed Items on the left to start the debate**.\n• If the Disagreed items donesn't exists\nFinish your response with exactly: **There are not Disagreed Items to debate**.\n═════════════════════════════════════════════════════\n\nOutput must have **exactly 2 line**. Break line between each line.",
    "task4":" The debate ran across six rounds (Claim → Grounds → Warrant → Backing → Rebuttal → Qualifier).\nThe process is as follows:\n\n\"[debate_responses]\"\n\n================================================================\n⚖\uFE0F  DECISION LOGIC\n\nSTEP 1 · CONSENSUS\nUse each role’s **final stance reported in Round 6 (Qualifier)**.\n\nIf *all* roles now hold the **same** position:\n  • all choose “code should be retained”  → Resolution = Retain  \n  • all choose “code should not be retained”  → Resolution = Drop  \n→ decision_mode = \"Consensus\"\n\nOtherwise proceed to STEP 2 (“Forced”).\n\nSTEP 2 · FORCED\nRead every round and pick the outcome that is **best-supported** by:\n  a. strength & accuracy of cited textual evidence;  \n  b. precision / usefulness of the proposed code;  \n  c. concessions or shifts revealed in Rebuttal & Qualifier.  \n\n================================================================\nPlease output your response strictly in the following JSON format:\n\n{\n  \"decision_mode\": \"Consensus\" | \"Forced\",\n  \"Resolution\": \"Retain\" | \"Drop\",\n  \"final_code\": \"<code name | null>\",// If Resolution=\"Retain\": must be one of ALLOWED_CODES. If \"Drop\": must be null (JSON null, not a string).\n  \"evidence\": \"<30–60-token justification>\"// 1–3 concise sentences\n}\n(No extra keys or text.)\n",
    "Central Issue": "Please debate around the following central question:\n\n\"From your role’s perspective, should this disagree code be retained in the final data annotation?\"",
    "Central Issue": "Please debate around the following central question:\n\n\"From your role’s perspective, should this disagree code be retained in the final data annotation?\"",
    "human": ""
  },
  "role_debater": {
    "system": "You are participating in a multi-role coding debate.\n\nTarget Text (fixed for the session)\n-----------------------------------\n\"[Target Text]\"   # pre-numbered; quote lines as [Words or Sentence]\n\nDisagreement Code now in focus\n------------------------------\n\"[code and justification]\"\n\nRoles will speak one at a time, each following the Role prompt below.\n\nEveryone must abide by the following rules:\n• Directly quote the Target Text — either one full sentence or a key phrase of 1-8 words. Enclose every quotation in [] so that reviewers can verify it. Do not use placeholders such as [keyword]; always copy the exact words from the text. (e.g., [The interface encourages user trust.]) \n• no external knowledge.",
    "debate_round":
    {
      "1": "Please make a clear decision based on your role’s perspective:\n\n**##Your task:**\n\n**Should this disagree code be retained in the final data annotation?**\n\n**## Output Format:**\n\nYou can only choose one of the following positions:\n\n- ✅ Yes, the code should be retained.\n- ❌ No, the code should not be retained.\n\nBe concise — No explanation needed here",
      "2": "##Your task:\nProvide factual evidence from the target text that directly supports your position in Round 1.\n\nYou should:\n\n- Identify one or more specific phrases, sentences, or expressions from the target text.\n- Focus only on **observable, textual facts** — avoid reasoning or interpretation.\n- Choose content that has a **strong and explicit connection** to your claim (retain or remove the code).\n\n- Review every other role’s last reply, extract the 1–2 pivotal sentences, and begin your response with a one-sentence recap of the point you’re addressing (you may quote a key phrase).\nResponses from other roles in the previous round:\n\"[response]\"\n\n##Output Format:\nWrite 1–3 sentences quoting or paraphrasing the most relevant parts of the original text.\n\nYou must ensure your evidence **aligned** with the disputed code under debate.",
      "3": "\uD83D\uDD17 Warrant (Reasoning Rule or Logic)\n\nThe reasoning principle or general assumption that connects the evidence (Ground) to your claim.\n\n##Your task:\nExplain **why** the evidence you identified in Round 2 logically supports your position in Round 1.\n\nThis is not about what you saw — it's about **why what you saw matters**.\n\nYou may consider:\n\n- Annotation principles (e.g., clarity, distinctiveness, usefulness)\n- Common assumptions in the task domain (e.g., subjective language signals sentiment)\n- Reasoning patterns (e.g., if X happens, then it typically means Y)\n- What would be lost if the evidence is ignored\n- Review every other role’s last reply, extract the 1–2 pivotal sentences, and begin your response with a one-sentence recap of the point you’re addressing (you may quote a key phrase).\nResponses from other roles in the previous round:\n\"[response]\"\n\n##Output Format:\nWrite 2–3 sentences explaining your **reasoning logic**.\n\nAvoid quoting the text again. Instead, show how your Ground leads to your Claim through generalizable rules or annotation standards.",
      "4": "Backing (Theory, Principle, Standard)\n\nThe general principle or authority that supports the reasoning logic you presented in Round 3.\n\n##Your task:\nSupport your Warrant by referring to a known **theory, annotation guideline, research practice, task standard, or domain assumption**.\n\nYour Backing should answer the question:\n\n**\"Why is your reasoning logic valid and worth trusting?\"**\n\nYou may consider:\n\n- Annotation schema or task instructions\n- Published guidelines, research papers, or frameworks\n- Common industry or domain assumptions\n- Collective practices from expert annotators\n- Review every other role’s last reply, extract the 1–2 pivotal sentences, and begin your response with a one-sentence recap of the point you’re addressing (you may quote a key phrase).\nResponses from other roles in the previous round:\n\"[response]\"\n\n##Output Format:\nWrite 1–2 sentences that reference a general principle or known standard.\n\nAvoid repeating your reasoning; instead, provide **evidence that your reasoning rule is widely accepted or justified**.",
      "5": "Rebuttal (Counterposition & Boundary Conditions)\n\nRespond to opposing views and recognize legitimate limits to your own claim.\n\n##Your task:\nCritically reflect on the alternative position (e.g., those who claimed this disagree code should be removed).\n\nYou should:\n\n- Argue why that opposing position is flawed, limited, or misaligned with task goals.\n- OR acknowledge any reasonable conditions under which your own claim might not hold.\n- Your rebuttal can mix **counterattack** (against others’ claims) and **boundary setting** (on your own claim).\n- Review every other role’s last reply, extract the 1–2 pivotal sentences, and begin your response with a one-sentence recap of the point you’re addressing (you may quote a key phrase).\nResponses from other roles in the previous round:\n\"[response]\"\n\n##Output Format:\nWrite 2–3 sentences.\n\nYou may begin with phrases such as:\n\n- “While some may argue that...”\n- “This perspective overlooks...”\n- “My claim may not apply if...”\n- “However, in cases where..., I agree the code may be unnecessary.”",
      "6": "Qualifier (Final Position & Applicability)\n\nIndicate whether your position has changed, and specify the conditions or limitations under which your judgment applies.\n\n##Your task:\nStep 1 — Choose one of the following to express your final stance:\n\n- ✅ My position remains unchanged. I still believe the code should [be retained / not be retained].\n- \uD83D\uDD04 My position has shifted. Now I believe the code should [be retained / not be retained].\n\nStep 2 — Add a sentence to qualify your position.\n\nYou may include:\n\n- When the code **should** or **should not** apply\n- In what type of task or context your view is relevant\n- Your level of certainty (e.g., always, usually, rarely, only when...)\n- Review every other role’s last reply, extract the 1–2 pivotal sentences, and begin your response with a one-sentence recap of the point you’re addressing (you may quote a key phrase).\nResponses from other roles in the previous round:\n\"[response]\"\n\n##Output Format:\nWrite 2–3 sentences in total:\n\n1. Begin with your selected base sentence from Step 1.\n2. Follow with one or two sentences that define the **conditions** or **degree of certainty** under which your judgment applies.\n\nYou may use expressions like:\n\n- “...but only when...”\n- “...except in cases where...”\n- “...especially if...”\n- “...always/usually/rarely applies in...”"
    }
  }
}
